{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WncmkCr_3JBT"
      },
      "source": [
        "Predicción de la evolución de la diabetes en pacientes usando MLP\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsCKpfnR3JBZ"
      },
      "source": [
        "Se desea construir um modelo de regresión no lineal (redes neuronales artificiales) que permita pronósticar el progreso de la diabetes con un horizonte de doce meses con base en variables físicas y pruebas de laboratorio. Véase https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sF_eFS63JBa"
      },
      "source": [
        "En este problema se tiene una base de datos de diez variables base (edad, sexo, índice de masa corporal, presión arterial, y seis variables medidas en sangre) para 442 pacientes, y un índice que mide el progreso de la diabetes un año después de la prueba. La columna Y es la variable explicada."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Solución**"
      ],
      "metadata": {
        "id": "ph0992K5Sk0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero realizamos la importación de las librerias y elementos adicionales"
      ],
      "metadata": {
        "id": "EbaEMT-bSoTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import pytest\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_selector\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "kaSKbt5RSieF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos la lectura del archivo alojado en el repositorio, y posterior a esto aplicamos un `ColumnTransformer` con el objetivo de \"estandarizar\" los datos y brindarle al algoritmo datos mucho más eficientes. Por último realizamos el `train_test_split` con un set de testeo del 20%. "
      ],
      "metadata": {
        "id": "H2dkyrbRThUr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fw1vt1L-3JBb"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# La muestra se encuentra dividida en tres partes:\n",
        "#\n",
        "#   * X_train, y_true_train: es la muestra para estimar los parametros optimos\n",
        "#\n",
        "#   * X_test, y_true_test: es la muestra para seleccionar la mejor configuración\n",
        "#\n",
        "#   * X_val, y_true_val: es la muestra para probar el modelo en productivo\n",
        "#\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/diabetes.csv\")\n",
        "\n",
        "column_trans = ColumnTransformer(\n",
        "    [\n",
        "       (\"minmaxscaler\", MinMaxScaler(feature_range=(0, 0.5)), make_column_selector(dtype_include=np.number)),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "X_trans=column_trans.fit_transform(df)\n",
        "\n",
        "names_col=list(df.columns)\n",
        "\n",
        "data=pd.DataFrame(X_trans,columns=names_col)\n",
        "\n",
        "\n",
        "\n",
        "y=data.pop(\"target\")\n",
        "X=data.copy()\n",
        "\n",
        "X_train, X_test, y_true_train, y_true_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.30,\n",
        "    random_state=177,\n",
        ")\n",
        "\n",
        "X_test, X_val, y_true_test, y_true_val = train_test_split(\n",
        "    X_test,\n",
        "    y_true_test,\n",
        "    test_size=0.50,\n",
        "    random_state=177,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos un `GridSearchCV`con el fin de establecer un enmallado de hiperparametros en donde varia la capa oculta, el random_state, la función de activación y el solver utilizado. Esto con el fin de encontrar el modelo que mejor predicción realiza. "
      ],
      "metadata": {
        "id": "k43LrPhdUAdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "estimators=[(\"m\",MLPRegressor(max_iter=100,learning_rate='adaptive',learning_rate_init=0.001,activation='identity',solver='adam'))]\n",
        "\n",
        "pipeline= Pipeline(\n",
        "    steps=estimators,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "param_grid = [\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Primera malla de parámetros\n",
        "    {\n",
        "        \"m__hidden_layer_sizes\": [(1,),(2,),(3,),(4,),(5,)],\n",
        "        \"m__random_state\": [1000, 1001, 1002, 1003, 1004, 1005],\n",
        "        #\"m__activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
        "        #\"m__solver\": ['lbfgs', 'sgd', 'adam'],\n",
        "    },\n",
        "]\n",
        "\n",
        "gridSearchCV = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=5)\n",
        "\n",
        "gridSearchCV.fit(X_train,y_true_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfbq_16G_K6s",
        "outputId": "01d0d612-8620-4874-d596-725edab84977"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('m',\n",
              "                                        MLPRegressor(activation='identity',\n",
              "                                                     learning_rate='adaptive',\n",
              "                                                     max_iter=100))]),\n",
              "             param_grid=[{'m__hidden_layer_sizes': [(1,), (2,), (3,), (4,),\n",
              "                                                    (5,)],\n",
              "                          'm__random_state': [1000, 1001, 1002, 1003, 1004,\n",
              "                                              1005]}])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El mejor estimador es el que cuenta con una activación de tangente hiperbolica, con dos capas ocultas y una tasa de aprenizaje adaptativa y un solver lbfgs. "
      ],
      "metadata": {
        "id": "vw9dewaCWSYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearchCV.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSOFJVPJCyCH",
        "outputId": "104c2fb9-4b25-4a07-e52c-d1aba7161b51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('m',\n",
              "                 MLPRegressor(activation='identity', hidden_layer_sizes=(3,),\n",
              "                              learning_rate='adaptive', max_iter=100,\n",
              "                              random_state=1004))])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test=gridSearchCV.predict(X_test)"
      ],
      "metadata": {
        "id": "1zYvlG4vFyhi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos el error cuadrático medio"
      ],
      "metadata": {
        "id": "3aaSAnsvWiqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "evPNkpE43JBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38316d3-5d64-4201-f46d-ee45e159dc14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#\n",
        "# Use la muestra (X_train, y_true_train) para la estimación\n",
        "# de los pesos óptimos de la red neuronal.\n",
        "#\n",
        "# Seleccione el modelo óptimo como aquel que minimice el error\n",
        "# cuadrático medio para la muestra (X_test, y_true_test).\n",
        "#\n",
        "# Considere únicamente modelos desde una (1) hasta (5) \n",
        "# neuronas en la capa oculta. Considere únicamente las\n",
        "# siguientes semillas para inicializar la red neuronal\n",
        "# 1000, 1001, 1002, 1003, 1004, 1005.\n",
        "#\n",
        "# Compute el error cuadrático medio para la muestra\n",
        "# (X_val, y_true_val). Esta muestra representa la operación\n",
        "# del modelo en productio\n",
        "# \n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# >>> Inserte su codigo aquí >>>\n",
        "\n",
        "mse_val=mean_squared_error(y_true_test, y_pred_test)\n",
        "\n",
        "#print(\"Error obtenido :\", mse_val)\n",
        "\n",
        "# <<<\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "pytest.approx(mse_val, 0.0001) == 0.009535"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nteract": {
      "version": "0.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "MATEO_prediccion_de_la_evolucion_de_la_diabetes_usando_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}